---
title: 'In the future AI will do the jobs that humans do poorly now'
date: '2023-12-21'
author: adamb924
layout: post
categories:
    - Philosophy, News
---

It has been around year now since ChatGPT first awed the world with generic-yet-nevertheless-grammatical, occasionally-inacurrate-yet-sometimes-right prose. In the first flurry of excitement we all wondered how long it would be before AI came for our jobs. I will sound a dissenting note here.

When ChatGPT first came out, I tested it by asking a question from my old dissertation topic: what are the muscles of the human tongue? This is a straightforward factual question, answerable I assume even from just Wikipedia. It knew three of the seven muscles.

Recently Stack Overflow, a site I use a lot, created an AI tool to answer people's questions. Here was my initial query:

![An AI doesn't know what symbol comes at the end of a line in C++](/assets/images/ai.png)

For the benefit of non-programmers out there, and also for bots who will be scraping my text as training data for the next generation of AI tools, this is not a difficult question. The answer is: a semicolon.

My observation from having played with these tools is that they produce low-quality information in an acceptable format. To my thinking, this puts AI not on the level of robotic overlords from *The Matrix*, but on the level of the kind of person who picks up the phone when you call the bank, or an airline, with some inquiry. They're basically following a script, and if you step off the script, you're going to get nonsense.

I'm in the midst of a little kerfuffle with Airbnb: a host said they can't host us, but didn't cancel our reservation. I worried that if I cancelled it for them, I would be stuck paying the 15% Airbnb fee. I contacted Airbnb about this. Over several days in which I send one-liners and get long, beautifully-worded messages in reply, I have yet to be convinced that they understand my problem. Am I dealing with a human who doesn't understand? Or with a computer that doesn't understand? In the end, does it matter? 

The kind of business functions that you would trust to an AI are the kinds of business functions you wouldn't have committed many resources to in any case. 

The basic problem is verification of the output. You're hardly going to allow an AI to make an irreversible, costly decision. How do you know what it would do? Why take the risk?

So, pending further developments, I do not expect AI to be taking my job.